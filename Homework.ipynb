{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1.  Spectral features (3 points out of 10)\n",
    "\n",
    "\n",
    "Prerequisites: install librosa and pandas through pip (you can do that inside a Jupyter notebook by running a command ```!pip install librosa```). \n",
    "\n",
    "We are going to load the dataset metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "genre_dataset = pd.read_csv(\"genre_dataset_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Exercise 2a. Extract at least three low-level spectral features of your choice. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"genres_audio\"\n",
    "feature_list = []\n",
    "for filename in os.listdir(dirname):\n",
    "    y, sr = librosa.load(os.path.join(dirname, filename))\n",
    "\n",
    "    \n",
    "    #add your feature extraction code here \n",
    "    feature_rms = librosa.feature.rms(y=y)\n",
    "    feature_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    feature_bandw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    feature_chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    \n",
    "    feature_list.append([filename, feature_rms, feature_centroid, feature_bandw, feature_chroma])\n",
    "    \n",
    "# create a dataframe with your features\n",
    "features = pd.DataFrame(feature_list, columns = ['filename','feature_rms', 'feature_centroid', 'feature_bandw', 'feature_chroma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(4):\n",
    "    fig, ax = plt.subplots(nrows=4, sharex=True)\n",
    "    times = librosa.times_like(features.feature_rms[i].size)\n",
    "    ax[0].title.set_text(features.filename[i])\n",
    "    ax[0].semilogy(times, features.feature_rms[i][0], label='RMS Energy')\n",
    "    ax[0].legend()\n",
    "    ax[1].semilogy(times, features.feature_centroid[i][0], label='Centroid')\n",
    "    ax[1].legend();\n",
    "    ax[2].semilogy(times, features.feature_bandw[i][0], label='Bandw')\n",
    "    ax[2].legend();\n",
    "    ax[3].semilogy(times, features.feature_chroma[i][0], label='Chroma')\n",
    "    ax[3].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join your features with the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dataset_with_features = genre_dataset.merge(features, left_on=\"filename\", right_on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dataset_with_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [x for x in genre_dataset_with_features.columns.to_list() if x.startswith('feature_')]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_means(row):\n",
    "    for key in row.keys():\n",
    "        if key.startswith('feature_'):\n",
    "            row[key] = row[key][0].mean()\n",
    "    return row\n",
    "\n",
    "genre_with_features = genre_dataset_with_features.drop(columns='filename')\n",
    "genre_features = genre_with_features.apply(col_means, axis=1)\n",
    "genre_features[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 2b. Visualize your feature distributions across genre.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data=genre_features, x=\"feature_centroid\", hue=\"genre\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=genre_features, x=\"feature_rms\", hue=\"genre\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=genre_features, x=\"feature_rms\", y=\"feature_centroid\", hue=\"genre\",kind=\"kde\",height=8.27, aspect=11.7/8.27);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=genre_features, x=\"feature_bandw\", y=\"feature_chroma\", hue=\"genre\",kind=\"kde\",height=8.27, aspect=11.7/8.27);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Exercise 2c. Do you have an explanations for the distributions that you observed?</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'>Using several features increases chances to distinguish genre.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Genre and chords (4 points out of 10)\n",
    "\n",
    "In this homework, we will explore a small dataset of 60 songs with genre labels. You received a folder with music files (one minute excerpts), a folder with automatically extracted chords that were parsed for you into chord root, chord triad type and chord extension, and genre annotations in a CSV file.\n",
    "\n",
    "\n",
    "Prerequisites: install **pandas, scikit learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Design and extract some features based on the extracted chords (you might try number of unique chords or chord stems, consider summing up chord durations for a specific chord type, etc.) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chord_file = pd.read_csv(\"chords/309.csv\")\n",
    "example_chord_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_chord_file['chord'].unique())\n",
    "print(example_chord_file['chord_root'].count())\n",
    "#example_chord_file['chord_duration'].sum(axis=1).where(example_chord_file['chord_triad'] == 'm')\n",
    "#example_chord_file['chord_duration'].sum()\n",
    "example_chord_file['chord_duration'].where(example_chord_file['chord_triad'] == 'm').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"chords\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=[]\n",
    "chordfiles = os.listdir(\"chords\")\n",
    "for filename in chordfiles: \n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        chords = pd.read_csv(os.path.join(\"chords\", filename), sep=',')\n",
    "        #chords.drop('.ipynb_checkpoints', axis=1)\n",
    "        #... design at least 5 features based on chords here \n",
    "\n",
    "        feature1 = chords['chord'].unique().size\n",
    "        feature2 = chords['chord_root'].unique().size\n",
    "        #feature3 = chords['chord_duration'].where(chords['chord_triad'] == 'dim').sum()\n",
    "        #feature4 = chords['chord_duration'].where(chords['chord_triad'] == 'maj').sum()\n",
    "        feature5 = chords['chord_duration'].where(chords['chord_root'] == 'C').sum()\n",
    "        feature6 = chords['chord_duration'].where(chords['chord_root'] == 'C#').sum()\n",
    "        feature7 = chords['chord_duration'].where(chords['chord_root'] == 'A').sum()\n",
    "        feature8 = chords['chord_duration'].where(chords['chord_root'] == 'D').sum()\n",
    "        feature9 = chords['chord_duration'].where(chords['chord_triad'] == 'm').sum()\n",
    "        feature10 = chords['chord'].count()\n",
    "\n",
    "        song_file_id = filename.split(\".\")[0] + '.mp3'\n",
    "        #feature_list.append([song_file_id, feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8, feature9,feature10])\n",
    "        feature_list.append([song_file_id, feature1, feature2, feature5, feature6, feature7, feature8, feature9,feature10])\n",
    "\n",
    "# create a dataframe with your features\n",
    "features = pd.DataFrame(feature_list, columns = ['filename','chord_number', 'chord_root_number','C','Csh','A','D', 'm', 'chord_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 2. Cluster the music files based on your features. Choose a number of clusters of your liking. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we remove the file ids from cluster variables\n",
    "features_without_labels = features.drop(\"filename\", axis=1)\n",
    "\n",
    "# Choose your n_clusters here\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(features_without_labels)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_with_song_ids = pd.DataFrame(\n",
    "    {'song_ids': features.filename,\n",
    "     'chord_root_number': features.chord_root_number,\n",
    "     'chord_number': features.chord_number,\n",
    "     'chord_count': features.chord_count,\n",
    "     'm' : features.m,\n",
    "     'D' : features.D,\n",
    "     'KMeans_clusters': kmeans.labels_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered3 = cluster_with_song_ids.groupby('KMeans_clusters').head(3).sort_values('KMeans_clusters')\n",
    "print(clustered3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, Audio\n",
    "\n",
    "def show_audio_with_controls(cluster, file, file_path):\n",
    "    display(HTML(f\"{file} cluster {cluster}<p><audio controls style='width:100%;'><source src='{file_path}' type='audio/mpeg'></audio>\"))\n",
    "\n",
    "for cluster, file in clustered3[['KMeans_clusters', 'song_ids']].to_numpy():\n",
    "    show_audio_with_controls(cluster, file, 'music/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Listen to the songs in your clusters and describe the clusters that you found. What characteristics do they have? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'>Cluster 1 has more diversity on chords, cluster 3 has lower number of chords</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 3 Now use your extracted features to predict the genre of the song. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_annotations = pd.read_csv(\"genre_annotations.csv\")\n",
    "features_with_genre = genre_annotations.merge(features, left_on=\"song_id\", right_on=\"filename\")\n",
    "features_with_genre = features_with_genre.drop('filename', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_annotations.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_genre[13:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "for color in features_with_genre['genre'].unique():\n",
    "    ax.scatter(features_with_genre['m'].where(features_with_genre['genre'] == color)\n",
    "               , features_with_genre['D'].where(features_with_genre['genre'] == color)\n",
    "               , features_with_genre['chord_count'].where(features_with_genre['genre'] == color)\n",
    "               , label=color, alpha=0.8, edgecolors='none')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ay = fig.add_subplot(projection='3d')\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "for color in cluster_with_song_ids.KMeans_clusters.unique():\n",
    "    ay.scatter(cluster_with_song_ids[cluster_with_song_ids.KMeans_clusters==color]['m']\n",
    "               , cluster_with_song_ids[cluster_with_song_ids.KMeans_clusters==color]['D']\n",
    "               , cluster_with_song_ids[cluster_with_song_ids.KMeans_clusters==color]['chord_count']\n",
    "               , label=color, alpha=0.8, edgecolors='none')\n",
    "ay.legend()\n",
    "ay.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Train a model of your choice and evaluate it's performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X, y = features_with_genre.drop(columns=['genre', 'song_id']), features_with_genre['genre']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "neigh = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "score = neigh.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f\"Mean accuracy {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> What were your best features?  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> chord_count and duration of chords are the best features for classifying genre.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "In this section we will do automatic tagging using CNNs. We will use a pretrained model to extract tags (training a model would require a large amount of data, time and compute power, which is out of the scope of a homework). For this exercise you will use your own musical archive (the audio files that you have on your computer). If you do not have any music stored on your device, try downloading some of your playlists with spotDL library.\n",
    "\n",
    "Prerequisites: install **musicnn** package with pip. Optionally, you might need **wordcloud**, **mlextend**, **pandas**, **spotdl** packages as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 1. Read this paper on automatic tagging (https://arxiv.org/pdf/1711.02520.pdf) and answer the following questions: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Do you have an idea why the PR-AUC is that low (~35) on MagnaTagATune dataset (hint: think about the labels)? \n",
    "\n",
    "#### <font color='green'>MagnaTagAtune dataset has binary labels</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) You want to train a CNN for chord extraction from mel-spectrograms. Would you rather use filters that stretch vertically or horizontally? Why?\n",
    "\n",
    "#### <font color='green'>For chord extraction combination of both vertical and horizontal filters is prefferable as patterns in spectrograms are occurring at different time-frequency scales</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) In the paper, the findings were extrapolated to larger dataset using a linear regression model. Based on this, what cutoff point would you use for dataset size, from which you would recommend using raw audio to train the model?\n",
    "\n",
    "#### <font color='green'>Based on 1.2M-songs results wave form outperforms spectrogram at around 600~700k songs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 2. In this exercise, we will use a python package which was developed based on research in the paper you just read. We will extract the tags from your own musical archive. Make sure you have musicnn package installed. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install musicnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import musicnn\n",
    "from musicnn.tagger import top_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now parse a folder from your computer that contains some music (possibly, the folder where Spotify stores music for offline listening)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "music_folder = \"my_music\"\n",
    "\n",
    "#replace with your music extensions if necessary\n",
    "music_files = glob.glob(music_folder + '/*.mp3', recursive=True)\n",
    "len(music_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the tags from each file in this folder. This may take a while depending on your machine, mostly due to spectrogram extraction. If it takes too long, may be reduce the amount of music you give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = []\n",
    "for music_file in music_files:\n",
    "    tags = top_tags(music_file, model='MSD_musicnn', topN=5)\n",
    "    tag_list.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 3. Analyze your results. Visualize the tags in at least three different ways (you can use word cloud, histograms, LDA). Describe your findings. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get you started, here is a possible way to analyze this data: frequent itemset mining. You will need ohe_df_top library installed in order to do this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, let's create a pandas dataframe from our list of tags\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tag_list, columns = [f\"tag{x}\" for x in range(1,len(tag_list[0])+1)]) \n",
    "\n",
    "#next, let's find how many distinct tags out of 50 possible tags we have got\n",
    "unique_tags_by_column = []\n",
    "for i in range(1,len(tag_list[0])):\n",
    "    unique_tags_by_column.extend(list(df[f\"tag{i}\"].unique()))\n",
    "unique_tags = set(unique_tags_by_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's transform our dataset into one-hot encoded form suitable for mlxtend library\n",
    "def encode_ohe(df):\n",
    "    ohe_values = []\n",
    "    for row in df.to_numpy():\n",
    "        rowset = set(row)\n",
    "        labels = {}\n",
    "        no_intersection = list(unique_tags - rowset)\n",
    "        intersection = list(unique_tags.intersection(rowset))\n",
    "        for itm in no_intersection:\n",
    "            labels[itm] = 0\n",
    "        for itm in intersection:\n",
    "            labels[itm] = 1\n",
    "        ohe_values.append(labels)\n",
    "    return pd.DataFrame(ohe_values)\n",
    "\n",
    "ohe_df = encode_ohe(df)\n",
    "ohe_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df_top = encode_ohe(df[['tag1', 'tag2']])\n",
    "columns0 = [x for x, y in ohe_df_top.sum().reset_index().to_numpy() if y == 0]\n",
    "ohe_df_top = ohe_df_top.drop(columns=columns0)\n",
    "ohe_df_top.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud().generate_from_frequencies(ohe_df.sum().to_dict())\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate_from_frequencies(ohe_df_top.sum().to_dict())\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
    "freq_items.sort_values('support', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items_top = apriori(ohe_df_top, min_support=0.2, use_colnames=True, verbose=1)\n",
    "freq_items_top.sort_values('support', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
    "rules.sort_values('leverage', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about your music collection on the basis of these rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'>According musicnn my collection consist mostly of rock/alternative/electronic/instrumental genre while indeed it contains few classical songs.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize your tags in at least two other ways in addition to the association rule mining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(ohe_df.corr(),annot=True)\n",
    "plt.title('Correlation Matrix of tags');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(ohe_df_top.corr(),annot=True)\n",
    "plt.title('Correlation Matrix of tags');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = np.concatenate( tag_list, axis=0 )\n",
    "plt.figure(figsize=(26,6))\n",
    "sns.histplot(data=t_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
